# [AI] Framework

@(AI)[Framework]

[TOC]

 OpenCL -> OpenCL™ Drivers and Runtimes for Intel® Architecture(intel-opencl-r5.0 (SRB5.0) -> clDNN
 srb5: 
- Intel® SDK for OpenCL™ Applications Package
- Driver and library(runtime) packages

Compute Library for Deep Neural Networks (clDNN) 
clDNN包含高度優化的構建塊，用C和C ++接口實現卷積神經網絡（CNN）
->
 Intel Deep-Learning Deployment Toolkit : 作為英特爾Computer Vision SDK的一部分
     簡化開發 - 使用統一的API快速將任何深度學習培訓模型與您的應用程序邏輯集成在一起。
     最大限度地提高性能 - 降低整體佔地面積並優化您選擇的基於英特爾®架構的硬件的性能。
     

##
- 命令式编程（imperative programming，比如Torch
- 声明式编程（declarative programming，比如Caffe，theano和TensorFlow）
命令式编程上MXNet提供张量运算
声明式编程中MXNet支持符号表达式

## Greengrass
執行 AWS Greengrass 核心的裝置可做為與其他裝置 (已安裝 AWS IoT 裝置開發套件) 通訊的中樞
AWS Greengrass 核心裝置和啟用 AWS IoT 裝置開發套件的裝置都可設定成在 Greengrass 群組中彼此通訊。
如果 Greengrass 核心裝置與雲端的連線中斷，Greengrass 群組中的裝置可繼續透過本機網路彼此通訊。
Greengrass 群組可代表建築物的一層樓、一輛貨車或一個家。

## 隐马尔可夫模型

霍金曾经说过
多写一个公式，就会少一半的读者。所以时间简史这本关于物理的书和麦当娜关于性的书卖的一样好。我会效仿这一做法，写最通俗易懂的答案。


假设我们开始掷骰子，我们先从三个骰子里挑一个，挑到每一个骰子的概率都是1/3。然后我们掷骰子，得到一个数字，1，2，3，4，5，6，7，8中的一个。不停的重复上述过程，我们会得到一串数字，每个数字都是1，2，3，4，5，6，7，8中的一个。例如我们可能得到这么一串数字（掷骰子10次）：1 6 3 5 2 7 3 5 2 4这串数字叫做可见状态链。但是在隐马尔可夫模型中，我们不仅仅有这么一串可见状态链，还有一串隐含状态链。在这个例子里，这串隐含状态链就是你用的骰子的序列。比如，隐含状态链有可能是：D6 D8 D8 D6 D4 D8 D6 D6 D4 D8一般来说，HMM中说到的马尔可夫链其实是指隐含状态链，因为隐含状态（骰子）之间存在转换概率（transition probability）。在我们这个例子里，D6的下一个状态是D4，D6，D8的概率都是1/3。D4，D8的下一个状态是D4，D6，D8的转换概率也都一样是1/3。这样设定是为了最开始容易说清楚，但是我们其实是可以随意设定转换概率的。比如，我们可以这样定义，D6后面不能接D4，D6后面是D6的概率是0.9，是D8的概率是0.1。这样就是一个新的HMM。

同样的，尽管可见状态之间没有转换概率，但是隐含状态和可见状态之间有一个概率叫做输出概率（emission probability）。就我们的例子来说，六面骰（D6）产生1的输出概率是1/6。产生2，3，4，5，6的概率也都是1/6。我们同样可以对输出概率进行其他定义。比如，我有一个被赌场动过手脚的六面骰子，掷出来是1的概率更大，是1/2，掷出来是2，3，4，5，6的概率是1/10。

和HMM模型相关的算法主要分为三类，分别解决三种问题：

1）知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子掷出的结果（可见状态链），我想知道每次掷出来的都是哪种骰子（隐含状态链）。

这个问题呢，在语音识别领域呢，叫做解码问题。这个问题其实有两种解法，会给出两个不同的答案。每个答案都对，只不过这些答案的意义不一样。第一种解法求最大似然状态路径，说通俗点呢，就是我求一串骰子序列，这串骰子序列产生观测结果的概率最大。第二种解法呢，就不是求一组骰子序列了，而是求每次掷出的骰子分别是某种骰子的概率。比如说我看到结果后，我可以求得第一次掷骰子是D4的概率是0.5，D6的概率是0.3，D8的概率是0.2.第一种解法我会在下面说到，但是第二种解法我就不写在这里了，如果大家有兴趣，我们另开一个问题继续写吧。

2）还是知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子掷出的结果（可见状态链），我想知道掷出这个结果的概率。

看似这个问题意义不大，因为你掷出来的结果很多时候都对应了一个比较大的概率。问这个问题的目的呢，其实是检测观察到的结果和已知的模型是否吻合。如果很多次结果都对应了比较小的概率，那么就说明我们已知的模型很有可能是错的，有人偷偷把我们的骰子給换了。

3）知道骰子有几种（隐含状态数量），不知道每种骰子是什么（转换概率），观测到很多次掷骰子的结果（可见状态链），我想反推出每种骰子是什么（转换概率）。这个问题很重要，因为这是最常见的情况。很多时候我们只有可见结果，不知道HMM模型里的参数，我们需要从可见结果估计出这些参数，这是建模的一个必要步骤。问题阐述完了，下面就开始说解法。（0号问题在上面没有提，只是作为解决上述问题的一个辅助）

Markov说明的是状态和状态间是markov chain
这就是为什么叫Hidden Markov Model。
「隱藏」二字便是指行蹤被隱藏了，狀態序列被隱藏了

若環境的變化是離目標更接近、我們就會給予一個正向反饋 (Positive Reward)，比如當機器投籃時越來越接近籃框；若離目標更遠、則給予負向反饋 (Negative Reward)，比如賽車時機器越開越偏離跑道。

雖然我們並沒有給予機器標籤資料，告訴它所採取的哪一步是正確、哪一步是錯誤的，但根據反饋的好壞，機器會自行逐步修正、最終得到正確的結果。

原則上無需考慮以前的狀態，當前狀態便已傳達出、所有能讓機器算出下一步最佳行動的資訊；簡單來說就是每一個事件只受到前一個事件的影響。打敗世界棋王的 Google AlphaGo 便是馬可夫假設一個成功的應用。

增強學習的機器學習方法當然還不僅止於此，多拉桿吃角子老虎機 (Multi-armed Bandit) 亦是增強學習的知名理論。

Bandit 是一個簡化過的增強學習方法，最重要的目標只有探索 (Explore) 和採集 (Exploit) 的平衡。這是什麼意思呢？

假設一個國家中有十家餐廳，每家餐廳提供的餐點份量相當不均、有些可能會偷工減料。某天該國突然湧入很多難民、因為餐券補助有限的關係，總共只能吃一百次餐廳，希望最後能餵飽最多的人。

顯然如果要吃到最多的東西，我們必須盡快找到「提供最大份量」的餐廳然後一直吃它就好了，其他黑心餐廳就不吃了。

如果把每家都吃一遍才確定份量最大的餐廳，會浪費掉太多餐券；然而若只吃了兩三家、就直接選比較高的一家一直吃，我們可能會漏掉真正提供最大份量的那一家餐廳。

解決 Bandit 問題的目標在於──有限的精力中，一部分精力會分配去探索未知的可能 (explore)、一部分則利用已知最好的策略不斷採集 (exploit)，演算法會透過不斷新增的環境數據進行調整，在兩者間尋求平衡、將利益最大化。


###
什麼是線性可分、和線性不可分的問題呢？比如說切開西瓜，可以發現裡面有白色的籽和黑色的籽；如果白籽和黑籽的分佈，能讓我們用一刀切分開，就是線性可分；如果是要用橢圓或曲線才能切開，就是線性不可分。因此線性可分的意義在於——我們能不能單純用一條直線把兩團資料點切分開。

由於感知機只能解決線性可分的問題，但現實中的分類問題通常是非線性的。為了針對線性不可分問題，類神經網路領域又發展出了不同的激發函數，比如使用 Sigmoid 函數，將「圖片中有貓/沒貓」的 0 和 1 標籤、進一步細化成可能的機率──「圖片中有貓/沒貓」的機率是在 0 到 1 之間的任意實數，比如 0.8807… (x=2)、0.2689… (x=-1)。

1986 年，Rumelhar 和 Hinton 等人提出了反向傳播算法，解決了神經網路所需要的複雜計算量問題，從而帶動了神經網路的研究熱潮。

此時的 Hinton 還很年輕，即便在後來神經網路遇到了瓶頸——反向傳播的優化 (找出誤差的最小值) 問題，學術界一度摒棄神經網路時，仍不離不棄對於神經網路的研究。也正是這股熱情，使得 30 年以後，正是他重新定義了神經網路、帶來了神經網路復甦的又一春；Hinton 也因此被稱為「深度學習之父」。

這邊，就讓我們來瞭解一下類神經網路究竟遇到了什麼問題，以致差點一厥不振。

我們在一開始提到過，類神經網路的原理就是先讓資料訊號通過網路，輸出結果後、計算其與真實情況的誤差。再將誤差訊號反向傳遞回去，透過梯度下降法，讓神經網路網路去逐一調整神經元的權重、不斷優化直到誤差最小、也就是代價函數達到最小值。

然而這種方法在神經網路具備多層的情況下，性能變得非常不理想，容易出現梯度消失問題——非線性問題的代價函數為非凸函數，求解時容易陷入局部最優解、而非全域最優解。

更糟的是，這種情況隨著神經網路層數的增加而更加嚴重，即隨著梯度逐層不斷消散、導致其對神經元權重調整的功用越來越小，所以只能轉而處理淺層結構（小於等於 3），從而限制了性能。

如果說為了不讓神經網路失真，僅能讓資料來回傳個 1、2 層，那還叫神經網路嗎？人類的大腦可就有數千萬層神經網路呢！與其使用理論難度高、訓練速度慢、實際結果也只能傳少少幾層的淺層神經網路的情況下不比其他方法好，不如使用其他的機器學習模型。


第二波浪潮: 淺層機器學習 (Shallow Learning)

神經網路由於遇到了優化的瓶頸，以致一度沒落。當時的學界只要看到出現「神經網路」字眼的論文或研究計畫，便會立刻貶斥。多層的神經網路是不可能的，而若採用僅有兩層的神經網路，不如使用其他更好上手、同樣只有兩層的「淺層」機器學習模型，

1990年代，各式各樣的淺層機器學習被提出，其中支撐向量機 (SVM, Support Vector Machines)最廣受歡迎。同樣是做資料的二分法，SVM 是怎麼做的呢？

SVM 理論上更加嚴謹完備，上手簡單，得到主流學術界的追捧。此時人人都不相信神經網路的可能性。而支持向量機 (SVM) 技術在圖像和語音識別方面的成功，使得神經網絡的研究陷入前所未有的低潮。

此時學術界的共識是： 多層神經網路是個完全沒有前途的死胡同。

究竟是誰重新改變了這一切、讓多層神經網路在2006年時換上「深度神經網路」(Deep Neural Network; 又稱 Deep Learning, 深度學習) 的新名字、聲勢浩大地捲土重來呢? 還記得我們提過、對於神經網路不離不棄研究三十年的 Hinton 嗎？他是怎麼解決這個問題的呢？

在現今，深度學習已是人工智慧領域中成長最為快速的類別。下一篇就讓我們來聊聊深度學習之父──多倫多大學 Geoffrey Hinton 教授的故事，看看他是如何耗費三十年的時間、終於讓類神經網路重迎一絲曙光。